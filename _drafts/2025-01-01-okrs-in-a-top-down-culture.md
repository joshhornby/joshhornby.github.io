---
title: "From Leading to Lagging: Rethinking Outcome Measurement"
date: 2025-08-07 08:00:00
tags: [culture, product]
sitemap:
    priority: 0.7
    changefreq: 'monthly'
    lastmod: "2025-08-07 T19:00:00+01:00"
---

I've spent much of my career watching teams struggle with outcome measurement. This pattern repeats across our industry: teams diligently track metrics, present detailed dashboards, and run thorough quarterly reviews, yet still find themselves surprised by actual business outcomes. The problem isn't a lack of measurement – it's that we're often measuring the wrong things at the wrong time.

In my experience, the root issue is that we've learned to celebrate the ceremony of measurement without building the mechanisms to make it meaningful. We track lagging indicators that tell us what already happened, while underinvesting in the leading indicators that could help us shape what happens next.

Start with outcomes that matter. When leadership hands down a fully baked roadmap, complete with initiatives and deadlines, they've skipped the most crucial step: working backwards for meaningful business results. Instead of asking "what should we build?", the question should be "what outcomes move the business forward?"

When organisations only superficially adopt outcome measurement, it shows up in how they track progress. They might talk about "outcomes" and "impact", but they're still focused on lagging indicators - metrics that tell you what already happened, like revenue or user growth. What's missing are the leading indicators - the early signals that predict whether you're on track to hit those business outcomes. Teams need both to make informed decisions.

The underlying reason this feels hollow comes down to incentives. If the organisation still values delivering initiatives over moving the business, measuring outcomes quickly becomes just another ritual, a layer of process that leaves the underlying priorities untouched.

It's easy for measurement to become disconnected from value creation. Teams track metrics that matter to leadership without understanding how those numbers connect to customer and business value. The key is identifying clear chains of cause and effect: which leading indicators predict the lagging outcomes we care about? What early signals tell us we're on the right path before the quarterly numbers come in?

This is where process reality diverges from process intent. The lived process is always the one people experience day to day, not what's written in the handbook. If the unspoken rule is "just say yes to the boss", it won't matter how you phrase the outcomes, they'll serve as another compliance checklist rather than an engine for a healthy challenge.

But there is power in working backwards from outcomes, even in a top-down environment. Starting with the desired result forces crucial conversations about causality. Teams must answer: What does success look like for the business? Which metrics actually predict that success? What leading indicators will tell us early if we're on track? These questions surface assumptions and trade-offs that might otherwise remain hidden.

This isn't a cure-all, but it does create leverage. A measurable outcome gives teams a reason to interrogate the plan, even when the work is dictated: is this project actually going to move the metric, or should we be prioritising something else? The discussion becomes less about how many things get shipped and more about whether anything actually changes.

Friction here is a healthy sign. When outcome measures provoke debate, disagreement, or even discomfort, it means the process is surfacing genuine trade-offs, not just generating reporting noise. The system is adjusting. This tension should be encouraged, not as conflict for its own sake, but as a signal that the team is engaged in real prioritisation, not passive delivery.

For any of this to work, teams need actual slack, room to think critically and challenge the status quo. If every quarter is a scramble to keep up, nobody's going to step back and question the plan. Measurement is just extra pressure, not a platform for smarter work.

None of these shifts overnight. If you're working in a command-and-control org, you're not going to suddenly get a blank slate. But you can start using measurement to force better conversations:

- Start with lagging indicators that directly measure business success.
- Identify the leading indicators that predict those outcomes.
- Map every initiative to both leading and lagging measures.
- Focus daily and weekly discussions on leading indicators.
- Use monthly or quarterly reviews to validate if leading indicators actually predicted outcomes.
- Celebrate teams that improve the predictive power of their metrics, not just those who hit their numbers.

## Real-world Examples of Outcome Measurement

I find it helpful to look at how different organisations approach outcome measurement, as it often reveals how context shapes what works. Here are two scenarios I've encountered:

TODO ADD EXAMPLES HERE

## Framework for Metric Selection

When evaluating potential metrics, I've found it useful to work through these questions:

1. **Causality Check**

- Does the metric actually predict the outcome you care about?
- Can you validate the relationship with historical data?
- What's your confidence interval on the prediction?

2. **Actionability Assessment**

- Can teams influence this metric directly?
- How quickly can you see the impact of changes?
- Are there obvious gaming risks?

3. **Implementation Viability**

- Can you measure this reliably?
- What's the cost of collecting and processing the data?
- How quickly can you detect significant changes?

For example, at cinch we initially tracked "number of support tickets" as a leading indicator of customer satisfaction. This failed the causality check – fewer tickets sometimes meant customers were stuck but not asking for help. We shifted to "time to resolution" combined with "successful self-service rate", which proved more predictive of renewal rates.

## When to Adjust Your Metrics

My experience is that organisations often hold onto metrics too long rather than not long enough. Here are signs it's time to reevaluate:

1. **Leading indicators stop predicting outcomes**This often happens when:

- Your product or user base has evolved significantly
- Market conditions have changed fundamentally
- You've optimised the metric to the point of diminishing returns

2. **Teams are optimising for measurement instead of outcomes**Watch for:

- Solutions designed around the metric rather than the problem
- Declining secondary metrics that weren't being tracked
- Teams feel constrained by metrics rather than guided by them

3. **Business priorities have shifted**Consider adjusting when:

- New strategic initiatives require different success criteria
- Competitive landscape changes demand new focus areas
- Organization has matured past current metrics

The point isn't that tracking outcomes will fix a top-down culture. But it can make the gap between activity and impact more visible. If you treat measurement as a lever, not a box-ticking exercise, it can help shift the conversation from "just do it" to "what's actually worth doing?" That's not compliance, it's the foundation of a healthier, more outcome-driven way of working.
